Maquina de vectores de soporte o Support Vector Machine es un metodo matematico, desarrollado en los a√±os 90 dentro del area de la computacion para aplicarlo a diversos modelos con el fin de poder contribuir a problemas de clasificacion multiple y regresion tanto en areas matematicas como fundamentalmente en problemas de computo directo. 

Su objetivo es la optimizacion o maximizacion dentro del descubrimiento de patrones, con el fin de poder esclarecer y distinguir caracteristicas propias de cada uno de los elementos involucrados en el modelo, a cada objeto con su caracterica se le denomina clase. El algoritmo es capaz en base a una serie de elementos matematicos de poder identifcar en base a entrenamiento a que clase pertenece cada dato entregado por un agente, para asi luego poder ir identificando de manera automaticamente las entradas correspondientes.

En el caso de un problema donde existen dos clases diferentes, un SVM se entrena de manera que la funcion maximize la habilidad de generalizacion. Esto se representa en la figura numero 2, donde se trata de encontrar una forma de separar las figuras cuadradas y redondas con el fin de identificar sus caracteristicas propias y finalmente encacillarlas.

Como se puede apreciar, el hiplerplano optimo engloba todos los elementos fundamentales dentro del SVM, lo que permite determinar la separacion maximizada representada por el margen que a su vez siempre busca la mayor division , para apreciar y clasificar de mejor manera en base a datos entregados. Los puntos mas proximos a la recta, son los que permiten localizar de buena manera los vectores de soporte que fundamentan la localizacion del hiperplano de separacion. Cabe destacar que todo dato de entrenamiento debe satisfacer la condicion de tener una distancia al hiperplano, mayor que la distancia de los vectores de soporte.

Haciendo nuevamente referencia  a la figura 2, la forma mas sencilla de realizar una separacion es mediante una linea recta, un plano recto o un hiperplano N-dimensional, como se denota en la figura. Sin embargo problemas computacionales referentes a tipos de aprendizajes actuales, exigen un trabajo de complejidad mayor como los casos de mayor cantidad de clases, curvas no lineales de separacion, clasificacion en mas de dos categorias o casos donde los conjuntos de datos no pueden ser separados completamente. Para esto se utiliza la funcion kernel, la cual pertenece a una amplia gamma de funciones matematicas que permiten convertir un problema de clasificacion no lineal a un problema de clasificacion en un espacio dimensional mayor. 

